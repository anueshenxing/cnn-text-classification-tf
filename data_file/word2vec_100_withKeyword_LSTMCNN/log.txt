word2vec训练的词向量，词向量维度为100，训练集为85000×0.8条新闻数据，有键词，模型为LSTM+CNN


word2vec训练的词向量，词向量维度为100，训练集为85000×0.8条新闻数据，有键词，模型为LSTM+CNN


2017-03-20T17:12:20.751779: loss 2.16187, acc 0.254795
2017-03-20T17:14:14.328433: loss 1.49974, acc 0.568904
2017-03-20T17:16:08.010680: loss 1.20366, acc 0.660685
2017-03-20T17:18:12.035882: loss 1.0104, acc 0.734452
2017-03-20T17:20:10.868608: loss 0.875351, acc 0.775548
2017-03-20T17:22:08.687966: loss 0.775501, acc 0.792534
2017-03-20T17:24:09.032179: loss 0.713334, acc 0.795959
2017-03-20T17:26:08.099613: loss 0.652042, acc 0.814795
2017-03-20T17:28:07.170181: loss 0.601651, acc 0.82411
2017-03-20T17:30:06.149978: loss 0.563686, acc 0.832671
2017-03-20T17:32:04.514235: loss 0.532743, acc 0.84137
2017-03-20T17:34:05.836153: loss 0.500676, acc 0.847877
2017-03-20T17:36:04.728539: loss 0.489759, acc 0.849658
2017-03-20T17:38:03.556026: loss 0.462906, acc 0.857192
2017-03-20T17:40:01.975532: loss 0.459489, acc 0.855068
2017-03-20T17:41:59.884391: loss 0.447827, acc 0.859315
2017-03-20T17:43:58.192703: loss 0.429305, acc 0.869315
2017-03-20T17:45:58.427030: loss 0.422345, acc 0.868699
2017-03-20T17:47:57.292732: loss 0.416034, acc 0.868562
2017-03-20T17:49:55.903534: loss 0.39714, acc 0.873767
2017-03-20T17:51:53.595081: loss 0.395672, acc 0.876644
2017-03-20T17:53:51.645779: loss 0.383935, acc 0.878562
2017-03-20T17:55:50.238709: loss 0.383354, acc 0.880205
2017-03-20T17:57:48.747015: loss 0.378975, acc 0.882192
2017-03-20T17:59:47.390400: loss 0.367849, acc 0.885685
2017-03-20T18:01:47.890771: loss 0.363825, acc 0.887808
2017-03-20T18:03:45.861218: loss 0.357324, acc 0.889795
2017-03-20T18:05:43.251111: loss 0.345288, acc 0.893082
2017-03-20T18:08:09.872730: loss 0.346752, acc 0.892603
2017-03-20T18:10:19.760382: loss 0.351237, acc 0.89
2017-03-20T18:13:24.396432: loss 0.33942, acc 0.89363
2017-03-20T18:16:34.106139: loss 0.342119, acc 0.893014
2017-03-20T18:19:54.348886: loss 0.338135, acc 0.893219
2017-03-20T18:23:11.149905: loss 0.335194, acc 0.896233
2017-03-20T18:26:20.287626: loss 0.332028, acc 0.896781
2017-03-20T18:29:34.703944: loss 0.332213, acc 0.895753
2017-03-20T18:32:42.445769: loss 0.328662, acc 0.896301
2017-03-20T18:35:53.388198: loss 0.330896, acc 0.897123
2017-03-20T18:39:07.283777: loss 0.324039, acc 0.898904
2017-03-20T18:42:26.042312: loss 0.322145, acc 0.899863
2017-03-20T18:45:33.464104: loss 0.317584, acc 0.900616
2017-03-20T18:48:45.446861: loss 0.311615, acc 0.903767
2017-03-20T18:51:54.890900: loss 0.323557, acc 0.900068
2017-03-20T18:55:05.552639: loss 0.314474, acc 0.901233
2017-03-20T18:58:19.178288: loss 0.313903, acc 0.902123
2017-03-20T19:01:36.159011: loss 0.321398, acc 0.900616
2017-03-20T19:04:46.136294: loss 0.308179, acc 0.904384
2017-03-20T19:06:58.823511: loss 0.310756, acc 0.904932
2017-03-20T19:08:57.221865: loss 0.302291, acc 0.907603
2017-03-20T19:11:08.960125: loss 0.314721, acc 0.903562
2017-03-20T19:13:28.014676: loss 0.306191, acc 0.905753
2017-03-20T19:15:37.136744: loss 0.305815, acc 0.90637
2017-03-20T19:17:32.381696: loss 0.304825, acc 0.907534
2017-03-20T19:19:27.418157: loss 0.303238, acc 0.908082
2017-03-20T19:21:23.426257: loss 0.307526, acc 0.905822
2017-03-20T19:23:20.719998: loss 0.300489, acc 0.909795
2017-03-20T19:25:15.225702: loss 0.302735, acc 0.907534
2017-03-20T19:27:11.652053: loss 0.304472, acc 0.90726
2017-03-20T19:29:06.946659: loss 0.308143, acc 0.90589
2017-03-20T19:31:01.798868: loss 0.30373, acc 0.908425
2017-03-20T19:32:56.474189: loss 0.301571, acc 0.909178
2017-03-20T19:34:53.210707: loss 0.303728, acc 0.907671
2017-03-20T19:37:04.051477: loss 0.302362, acc 0.908562
2017-03-20T19:39:03.288201: loss 0.304575, acc 0.908836
2017-03-20T19:40:58.166280: loss 0.302386, acc 0.908767
2017-03-20T19:42:53.852667: loss 0.298142, acc 0.910068
2017-03-20T19:44:48.444281: loss 0.296148, acc 0.910959
2017-03-20T19:46:42.871954: loss 0.308195, acc 0.907534
2017-03-20T19:48:38.318593: loss 0.300471, acc 0.909315
2017-03-20T19:50:33.385767: loss 0.291181, acc 0.910959
